{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"18784d60d3b7bdc2cf24a296519e9a93cb0c61fb"},"source":["## General information\n","\n","This kernel is a fork of my Keras kernel. But this one will use Pytorch.\n","\n","I'll gradually introduce more complex architectures.\n","\n","![](https://pbs.twimg.com/profile_images/1013607595616038912/pRq_huGc_400x400.jpg)"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","\n","from nltk.tokenize import TweetTokenizer\n","import datetime\n","import lightgbm as lgb\n","from scipy import stats\n","from scipy.sparse import hstack, csr_matrix\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from wordcloud import WordCloud\n","from collections import Counter\n","from nltk.corpus import stopwords\n","from nltk.util import ngrams\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import LinearSVC\n","from sklearn.multiclass import OneVsRestClassifier\n","import time\n","pd.set_option('max_colwidth',400)\n","\n","from keras.preprocessing.text import Tokenizer\n","from keras_preprocessing.sequence import pad_sequences\n","from sklearn.preprocessing import OneHotEncoder\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","from torch.autograd import Variable\n","import torch.utils.data\n","import random\n","import warnings\n","warnings.filterwarnings(\"ignore\", message=\"F-score is ill-defined and being set to 0.0 due to no predicted samples.\")\n","import re\n","from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import gc; gc.collect()\n","time.sleep(10)"]},{"cell_type":"code","execution_count":3,"metadata":{"_uuid":"bb40886b64534d7a8c0e424d3f2033e984ca9194","trusted":true},"outputs":[],"source":["def seed_torch(seed=1029):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":4,"metadata":{"_kg_hide-input":true,"_uuid":"2b77f6a1c831c98851143feb25c9903cb1154bf2","trusted":true},"outputs":[],"source":["train = pd.read_csv(\"../input/train.csv\")\n","test = pd.read_csv(\"../input/test.csv\")\n","sub = pd.read_csv('../input/sample_submission.csv')"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"28c5b2320f5ef863df3d0b4e4d9175c59bd61ef0"},"source":["## Data overview\n","\n","This is a kernel competition, where we can't use external data. As a result we can use only train and test datasets as well as embeddings which were provided by organizers."]},{"cell_type":"code","execution_count":5,"metadata":{"_uuid":"1558909b0a5c120c1d5ddc5be4f5a952fcb4971e","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Available embeddings: ['glove.840B.300d', 'GoogleNews-vectors-negative300', 'paragram_300_sl999', 'wiki-news-300d-1M']\n"]}],"source":["import os\n","print('Available embeddings:', os.listdir(\"../input/embeddings/\"))"]},{"cell_type":"code","execution_count":6,"metadata":{"_uuid":"0c7299c8895405ef00049595ead1ef89649ba71b","trusted":true},"outputs":[{"data":{"text/plain":["0    1225312\n","1      80810\n","Name: target, dtype: int64"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["train[\"target\"].value_counts()"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"cdbe2595e31608b72cfbdc8d4bfc75840bfe3a0d"},"source":["We have a seriuos disbalance - only ~6% of data are positive. No wonder the metric for the competition is f1-score."]},{"cell_type":"code","execution_count":7,"metadata":{"_uuid":"afaa845d44d72b9997ce037ab547ab4010701311","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>question_text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00002165364db923c7e6</td>\n","      <td>How did Quebec nationalists see their province as a nation in the 1960s?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000032939017120e6e44</td>\n","      <td>Do you have an adopted dog, how would you encourage people to adopt and not shop?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0000412ca6e4628ce2cf</td>\n","      <td>Why does velocity affect time? Does velocity affect space geometry?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>000042bf85aa498cd78e</td>\n","      <td>How did Otto von Guericke used the Magdeburg hemispheres?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0000455dfa3e01eae3af</td>\n","      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres?</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    qid  \\\n","0  00002165364db923c7e6   \n","1  000032939017120e6e44   \n","2  0000412ca6e4628ce2cf   \n","3  000042bf85aa498cd78e   \n","4  0000455dfa3e01eae3af   \n","\n","                                                                       question_text  \\\n","0           How did Quebec nationalists see their province as a nation in the 1960s?   \n","1  Do you have an adopted dog, how would you encourage people to adopt and not shop?   \n","2                Why does velocity affect time? Does velocity affect space geometry?   \n","3                          How did Otto von Guericke used the Magdeburg hemispheres?   \n","4      Can I convert montra helicon D to a mountain bike by just changing the tyres?   \n","\n","   target  \n","0       0  \n","1       0  \n","2       0  \n","3       0  \n","4       0  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["train.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"0817c86624cc43ea1df0eba310ba41f4f799f8da"},"source":["In the dataset we have only texts of questions."]},{"cell_type":"code","execution_count":8,"metadata":{"_uuid":"54a553b7e92a2a0a3d491ccf92b437011b813c85","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Average word length of questions in train is 13.\n","Average word length of questions in test is 13.\n"]}],"source":["print('Average word length of questions in train is {0:.0f}.'.format(np.mean(train['question_text'].apply(lambda x: len(x.split())))))\n","print('Average word length of questions in test is {0:.0f}.'.format(np.mean(test['question_text'].apply(lambda x: len(x.split())))))"]},{"cell_type":"code","execution_count":9,"metadata":{"_uuid":"7861669f72f36145c25911926a51bc688f51d473","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Max word length of questions in train is 134.\n","Max word length of questions in test is 87.\n"]}],"source":["print('Max word length of questions in train is {0:.0f}.'.format(np.max(train['question_text'].apply(lambda x: len(x.split())))))\n","print('Max word length of questions in test is {0:.0f}.'.format(np.max(test['question_text'].apply(lambda x: len(x.split())))))"]},{"cell_type":"code","execution_count":10,"metadata":{"_uuid":"1b1303137eb44cc0de3329921751c48209037562","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Average character length of questions in train is 71.\n","Average character length of questions in test is 71.\n"]}],"source":["print('Average character length of questions in train is {0:.0f}.'.format(np.mean(train['question_text'].apply(lambda x: len(x)))))\n","print('Average character length of questions in test is {0:.0f}.'.format(np.mean(test['question_text'].apply(lambda x: len(x)))))"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["from tqdm import tqdm\n","tqdm.pandas()\n","def build_vocab(sentences, verbose =  True):\n","    \"\"\"\n","    :param sentences: list of list of words\n","    :return: dictionary of words and their count\n","    \"\"\"\n","    vocab = {}\n","    for sentence in tqdm(sentences, disable = (not verbose)):\n","        for word in sentence:\n","            try:\n","                vocab[word] += 1\n","            except KeyError:\n","                vocab[word] = 1\n","    return vocab"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1306122/1306122 [00:04<00:00, 295293.06it/s]\n","100%|██████████| 1306122/1306122 [00:03<00:00, 390438.20it/s]"]},{"name":"stdout","output_type":"stream","text":["{'How': 261930, 'did': 33489, 'Quebec': 97, 'nationalists': 91, 'see': 9003}\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["sentences = train[\"question_text\"].progress_apply(lambda x: x.split()).values\n","vocab = build_vocab(sentences)\n","print({k: vocab[k] for k in list(vocab)[:5]})"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["import operator \n","\n","def check_coverage(vocab,embeddings_index):\n","    a = {}\n","    oov = {}\n","    k = 0\n","    i = 0\n","    for word in tqdm(vocab):\n","        try:\n","            a[word] = embeddings_index[word]\n","            k += vocab[word]\n","        except:\n","\n","            oov[word] = vocab[word]\n","            i += vocab[word]\n","            pass\n","\n","    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n","    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n","    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n","\n","    return sorted_x"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["from gensim.models import KeyedVectors\n","\n","news_path = '../input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n","embeddings_index = KeyedVectors.load_word2vec_format(news_path, binary=True)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 508823/508823 [00:01<00:00, 466081.21it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Found embeddings for 24.31% of vocab\n","Found embeddings for  78.75% of all text\n"]}],"source":["oov = check_coverage(vocab,embeddings_index)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"b82f366ef8b46b0115e9940c7966849023545733","trusted":true},"source":["As we can see on average questions in train and test datasets are similar, but there are quite long questions in train dataset."]},{"cell_type":"code","execution_count":16,"metadata":{"_kg_hide-input":true,"_uuid":"4f1838e686d67670bb6429b8b43619a69803fde8","trusted":true},"outputs":[],"source":["puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n"," '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n"," '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n"," '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n"," '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n","\n","def clean_text(x):\n","    x = str(x)\n","    for punct in puncts:\n","        x = x.replace(punct, f' {punct} ')\n","    return x\n","\n","def clean_numbers(x):\n","    x = re.sub('[0-9]{5,}', '#####', x)\n","    x = re.sub('[0-9]{4}', '####', x)\n","    x = re.sub('[0-9]{3}', '###', x)\n","    x = re.sub('[0-9]{2}', '##', x)\n","    return x\n","\n","mispell_dict = {\"aren't\" : \"are not\",\n","\"can't\" : \"cannot\",\n","\"couldn't\" : \"could not\",\n","\"didn't\" : \"did not\",\n","\"doesn't\" : \"does not\",\n","\"don't\" : \"do not\",\n","\"hadn't\" : \"had not\",\n","\"hasn't\" : \"has not\",\n","\"haven't\" : \"have not\",\n","\"he'd\" : \"he would\",\n","\"he'll\" : \"he will\",\n","\"he's\" : \"he is\",\n","\"i'd\" : \"I would\",\n","\"i'd\" : \"I had\",\n","\"i'll\" : \"I will\",\n","\"i'm\" : \"I am\",\n","\"isn't\" : \"is not\",\n","\"it's\" : \"it is\",\n","\"it'll\":\"it will\",\n","\"i've\" : \"I have\",\n","\"let's\" : \"let us\",\n","\"mightn't\" : \"might not\",\n","\"mustn't\" : \"must not\",\n","\"shan't\" : \"shall not\",\n","\"she'd\" : \"she would\",\n","\"she'll\" : \"she will\",\n","\"she's\" : \"she is\",\n","\"shouldn't\" : \"should not\",\n","\"that's\" : \"that is\",\n","\"there's\" : \"there is\",\n","\"they'd\" : \"they would\",\n","\"they'll\" : \"they will\",\n","\"they're\" : \"they are\",\n","\"they've\" : \"they have\",\n","\"we'd\" : \"we would\",\n","\"we're\" : \"we are\",\n","\"weren't\" : \"were not\",\n","\"we've\" : \"we have\",\n","\"what'll\" : \"what will\",\n","\"what're\" : \"what are\",\n","\"what's\" : \"what is\",\n","\"what've\" : \"what have\",\n","\"where's\" : \"where is\",\n","\"who'd\" : \"who would\",\n","\"who'll\" : \"who will\",\n","\"who're\" : \"who are\",\n","\"who's\" : \"who is\",\n","\"who've\" : \"who have\",\n","\"won't\" : \"will not\",\n","\"wouldn't\" : \"would not\",\n","\"you'd\" : \"you would\",\n","\"you'll\" : \"you will\",\n","\"you're\" : \"you are\",\n","\"you've\" : \"you have\",\n","\"'re\": \" are\",\n","\"wasn't\": \"was not\",\n","\"we'll\":\" will\",\n","\"didn't\": \"did not\",\n","\"tryin'\":\"trying\"}\n","\n","def _get_mispell(mispell_dict):\n","    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n","    return mispell_dict, mispell_re\n","\n","mispellings, mispellings_re = _get_mispell(mispell_dict)\n","def replace_typical_misspell(text):\n","    def replace(match):\n","        return mispellings[match.group(0)]\n","    return mispellings_re.sub(replace, text)\n","\n","# Clean the text\n","train[\"question_text\"] = train[\"question_text\"].apply(lambda x: clean_text(x.lower()))\n","test[\"question_text\"] = test[\"question_text\"].apply(lambda x: clean_text(x.lower()))\n","\n","# Clean numbers\n","train[\"question_text\"] = train[\"question_text\"].apply(lambda x: clean_numbers(x))\n","test[\"question_text\"] = test[\"question_text\"].apply(lambda x: clean_numbers(x))\n","\n","# Clean speelings\n","train[\"question_text\"] = train[\"question_text\"].apply(lambda x: replace_typical_misspell(x))\n","test[\"question_text\"] = test[\"question_text\"].apply(lambda x: replace_typical_misspell(x))"]},{"cell_type":"code","execution_count":17,"metadata":{"_uuid":"9d081b2f0d46faf01a943c309568c27f92462f94","trusted":true},"outputs":[],"source":["max_features = 120000\n","tk = Tokenizer(lower = True, filters='', num_words=max_features)\n","full_text = list(train['question_text'].values) + list(test['question_text'].values)\n","tk.fit_on_texts(full_text)"]},{"cell_type":"code","execution_count":18,"metadata":{"_uuid":"33929a60e1872b73e40424daa1178a3d8fbf8f5a","trusted":true},"outputs":[],"source":["train_tokenized = tk.texts_to_sequences(train['question_text'].fillna('missing'))\n","test_tokenized = tk.texts_to_sequences(test['question_text'].fillna('missing'))"]},{"cell_type":"code","execution_count":19,"metadata":{"_uuid":"4330f6c01064b5fda4ca9661dc4f1cefb439cf75","trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["train['question_text'].apply(lambda x: len(x.split())).plot(kind='hist');\n","plt.yscale('log');\n","plt.title('Distribution of question text length in characters');"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"05c7e2c63afb343b64835432721a42f81dd53626"},"source":["We can see that most of the questions are 40 words long or shorter. Let's try having sequence length equal to 70 for now."]},{"cell_type":"code","execution_count":20,"metadata":{"_uuid":"15d7e3a2fb5fe5fb38da45ca3d0bd13c82b7eda5","trusted":true},"outputs":[],"source":["max_len = 72\n","maxlen = 72\n","X_train = pad_sequences(train_tokenized, maxlen = max_len)\n","X_test = pad_sequences(test_tokenized, maxlen = max_len)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"50ade6e2c4dab8ee4add2a9c080f132e012cedc7"},"source":["### Preparing data for Pytorch\n","\n","One of main differences from Keras is preparing data.\n","Pytorch requires special dataloaders. I'll write a class for it.\n","\n","At first I'll append padded texts to original DF."]},{"cell_type":"code","execution_count":21,"metadata":{"_uuid":"31839c56ed1d7945decf176c97b49f0205cc40af","trusted":true},"outputs":[],"source":["y_train = train['target'].values"]},{"cell_type":"code","execution_count":22,"metadata":{"_uuid":"69d325ea77439697e53143adef3a0da58e7f31f2","trusted":true},"outputs":[],"source":["def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"]},{"cell_type":"code","execution_count":24,"metadata":{"_uuid":"cca23aa2dc1207a6f08212ad8d87f8182e567e0e","trusted":true},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold\n","splits = list(StratifiedKFold(n_splits=4, shuffle=True, random_state=10).split(X_train, y_train))"]},{"cell_type":"code","execution_count":20,"metadata":{"_uuid":"744ee4a1fbc66cb47aae6a18f829dea284b860c9","trusted":true},"outputs":[],"source":["embed_size = 300\n","embedding_path = \"../input/embeddings/glove.840B.300d/glove.840B.300d.txt\"\n","def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n","embedding_index = dict(get_coefs(*o.split(\" \")) for o in open(embedding_path, encoding='utf-8', errors='ignore'))\n","# all_embs = np.stack(embedding_index.values())\n","# emb_mean,emb_std = all_embs.mean(), all_embs.std()\n","emb_mean,emb_std = -0.005838499, 0.48782197\n","word_index = tk.word_index\n","nb_words = min(max_features, len(word_index))\n","embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words + 1, embed_size))\n","for word, i in word_index.items():\n","    if i >= max_features: continue\n","    embedding_vector = embedding_index.get(word)\n","    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\WorkApp\\Anconda\\envs\\pytorch_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3400: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  if await self.run_code(code, result, async_=asy):\n"]}],"source":["embed_size = 300\n","EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n","def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n","embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n","\n","all_embs = np.stack(embeddings_index.values())\n","emb_mean,emb_std = all_embs.mean(), all_embs.std()\n","embed_size = all_embs.shape[1]\n","\n","word_index = tk.word_index\n","nb_words = min(max_features, len(word_index))\n","embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n","for word, i in word_index.items():\n","    if i >= max_features: continue\n","    embedding_vector = embedding_index.get(word)\n","    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 508823/508823 [00:05<00:00, 85210.76it/s]"]},{"name":"stdout","output_type":"stream","text":["Found embeddings for 33.16% of vocab\n","Found embeddings for  88.16% of all text\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["oov = check_coverage(vocab,embedding_index)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"cc553dd7ddbd3a81ed1a39084fdb4982b5887971","trusted":true},"outputs":[],"source":["embedding_path = \"../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt\"\n","def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n","embedding_index = dict(get_coefs(*o.split(\" \")) for o in open(embedding_path, encoding='utf-8', errors='ignore') if len(o)>100)\n","# all_embs = np.stack(embedding_index.values())\n","# emb_mean,emb_std = all_embs.mean(), all_embs.std()\n","emb_mean,emb_std = -0.0053247833, 0.49346462\n","embedding_matrix1 = np.random.normal(emb_mean, emb_std, (nb_words + 1, embed_size))\n","for word, i in word_index.items():\n","    if i >= max_features: continue\n","    embedding_vector = embedding_index.get(word)\n","    if embedding_vector is not None: embedding_matrix1[i] = embedding_vector"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["embedding_path = \"../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt\"\n","def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n","embedding_index = dict(get_coefs(*o.split(\" \")) for o in open(embedding_path, encoding='utf-8', errors='ignore') if len(o)>100)\n","all_embs = np.stack(embeddings_index.values())\n","emb_mean,emb_std = all_embs.mean(), all_embs.std()\n","embed_size = all_embs.shape[1]\n","\n","word_index = tk.word_index\n","nb_words = min(max_features, len(word_index))\n","embedding_matrix1 = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n","for word, i in word_index.items():\n","    if i >= max_features: continue\n","    embedding_vector = embedding_index.get(word)\n","    if embedding_vector is not None: embedding_matrix1[i] = embedding_vector"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["EMBEDDING_FILE = '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n","def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n","embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n","\n","all_embs = np.stack(embeddings_index.values())\n","emb_mean,emb_std = all_embs.mean(), all_embs.std()\n","embed_size = all_embs.shape[1]\n","\n","word_index = tk.word_index\n","nb_words = min(max_features, len(word_index))\n","embedding_matrix2 = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n","for word, i in word_index.items():\n","    if i >= max_features: continue\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None: embedding_matrix2[i] = embedding_vector\n","        \n"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"333429eaa0c7c057769518c8f1b0fefbb68f1d1d","trusted":true},"outputs":[],"source":["embedding_matrix = np.mean([embedding_matrix, embedding_matrix1,embedding_matrix2], axis=0)\n","del embedding_matrix1, embedding_matrix2"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"ed3cd4b2f73c7ed5d1896f6b43029c8efdd89d5e"},"source":["### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"23b0dcfa9bff61ef4c5aebd85f9521edd8f6009d","trusted":true},"outputs":[],"source":["class Attention(nn.Module):\n","    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n","        super(Attention, self).__init__(**kwargs)\n","        \n","        self.supports_masking = True\n","\n","        self.bias = bias\n","        self.feature_dim = feature_dim\n","        self.step_dim = step_dim\n","        self.features_dim = 0\n","        \n","        weight = torch.zeros(feature_dim, 1)\n","        nn.init.xavier_uniform_(weight)\n","        self.weight = nn.Parameter(weight)\n","        \n","        if bias:\n","            self.b = nn.Parameter(torch.zeros(step_dim))\n","        \n","    def forward(self, x, mask=None):\n","        feature_dim = self.feature_dim\n","        step_dim = self.step_dim\n","\n","        eij = torch.mm(\n","            x.contiguous().view(-1, feature_dim), \n","            self.weight\n","        ).view(-1, step_dim)\n","        \n","        if self.bias:\n","            eij = eij + self.b\n","            \n","        eij = torch.tanh(eij)\n","        a = torch.exp(eij)\n","        \n","        if mask is not None:\n","            a = a * mask\n","\n","        a = a / torch.sum(a, 1, keepdim=True) + 1e-10\n","\n","        weighted_input = x * torch.unsqueeze(a, -1)\n","        return torch.sum(weighted_input, 1)\n","    \n","class NeuralNet(nn.Module):\n","    def __init__(self):\n","        super(NeuralNet, self).__init__()\n","        \n","        hidden_size = 128\n","        \n","        self.embedding = nn.Embedding(max_features, embed_size)\n","        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n","        self.embedding.weight.requires_grad = False\n","        \n","        self.embedding_dropout = nn.Dropout2d(0.1)\n","        self.lstm = nn.LSTM(embed_size, hidden_size, bidirectional=True, batch_first=True)\n","        self.gru = nn.GRU(hidden_size*2, hidden_size, bidirectional=True, batch_first=True)\n","        \n","        self.lstm_attention = Attention(hidden_size*2, maxlen)\n","        self.gru_attention = Attention(hidden_size*2, maxlen)\n","        \n","        self.linear = nn.Linear(1024, 16)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(0.1)\n","        self.out = nn.Linear(16, 1)\n","        \n","    def forward(self, x):\n","        h_embedding = self.embedding(x)\n","        h_embedding = torch.squeeze(self.embedding_dropout(torch.unsqueeze(h_embedding, 0)))\n","        \n","        h_lstm, _ = self.lstm(h_embedding)\n","        h_gru, _ = self.gru(h_lstm)\n","        \n","        h_lstm_atten = self.lstm_attention(h_lstm)\n","        h_gru_atten = self.gru_attention(h_gru)\n","        \n","        avg_pool = torch.mean(h_gru, 1)\n","        max_pool, _ = torch.max(h_gru, 1)\n","        \n","        conc = torch.cat((h_lstm_atten, h_gru_atten, avg_pool, max_pool), 1)\n","        conc = self.relu(self.linear(conc))\n","        conc = self.dropout(conc)\n","        out = self.out(conc)\n","        \n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"efa73786bf93892a5c3f46329122c0c0275e4858","trusted":true},"outputs":[],"source":["m = NeuralNet()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"a29c7d10faaf54c58cda8a406cb31fb367816f6c","trusted":true},"outputs":[],"source":["def train_model(model, x_train, y_train, x_val, y_val, validate=True):\n","    optimizer = torch.optim.Adam(model.parameters())\n","\n","    # scheduler = CosineAnnealingLR(optimizer, T_max=5)\n","    # scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n","    \n","    train = torch.utils.data.TensorDataset(x_train, y_train)\n","    valid = torch.utils.data.TensorDataset(x_val, y_val)\n","    \n","    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n","    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n","    \n","    loss_fn = torch.nn.BCEWithLogitsLoss(reduction='mean').cuda()\n","    best_score = -np.inf\n","    \n","    for epoch in range(n_epochs):\n","        start_time = time.time()\n","        model.train()\n","        avg_loss = 0.\n","        \n","        for x_batch, y_batch in tqdm(train_loader, disable=True):\n","            y_pred = model(x_batch)\n","            \n","            \n","            loss = loss_fn(y_pred, y_batch)\n","\n","            optimizer.zero_grad()\n","\n","            loss.backward()\n","\n","            optimizer.step()\n","            avg_loss += loss.item() / len(train_loader)\n","            \n","        model.eval()\n","        \n","        valid_preds = np.zeros((x_val_fold.size(0)))\n","        \n","        if validate:\n","            avg_val_loss = 0.\n","            for i, (x_batch, y_batch) in enumerate(valid_loader):\n","                y_pred = model(x_batch).detach()\n","\n","                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n","                valid_preds[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n","            search_result = threshold_search(y_val.cpu().numpy(), valid_preds)\n","\n","            val_f1, val_threshold = search_result['f1'], search_result['threshold']\n","            elapsed_time = time.time() - start_time\n","            print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t val_f1={:.4f} best_t={:.2f} \\t time={:.2f}s'.format(\n","                epoch + 1, n_epochs, avg_loss, avg_val_loss, val_f1, val_threshold, elapsed_time))\n","        else:\n","            elapsed_time = time.time() - start_time\n","            print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n","                epoch + 1, n_epochs, avg_loss, elapsed_time))\n","    \n","    valid_preds = np.zeros((x_val_fold.size(0)))\n","    \n","    avg_val_loss = 0.\n","    for i, (x_batch, y_batch) in enumerate(valid_loader):\n","        y_pred = model(x_batch).detach()\n","\n","        avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n","        valid_preds[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n","\n","    print('Validation loss: ', avg_val_loss)\n","\n","    test_preds = np.zeros((len(test_loader.dataset)))\n","    \n","    for i, (x_batch,) in enumerate(test_loader):\n","        y_pred = model(x_batch).detach()\n","\n","        test_preds[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n","    # scheduler.step()\n","    \n","    return valid_preds, test_preds#, test_preds_local"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"2252ff85cae8b5096e7f10ccf64ce10299a18782","trusted":true},"outputs":[],"source":["x_test_cuda = torch.tensor(X_test, dtype=torch.long).cuda()\n","test = torch.utils.data.TensorDataset(x_test_cuda)\n","batch_size = 512\n","test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"9ec7632d3f2ef30b2e985a4662bc8178b9a49a94","trusted":true},"outputs":[],"source":["seed=1029\n","\n","def threshold_search(y_true, y_proba):\n","    best_threshold = 0\n","    best_score = 0\n","    for threshold in tqdm([i * 0.01 for i in range(100)], disable=True):\n","        score = f1_score(y_true=y_true, y_pred=y_proba > threshold)\n","        if score > best_score:\n","            best_threshold = threshold\n","            best_score = score\n","    search_result = {'threshold': best_threshold, 'f1': best_score}\n","    return search_result\n","\n","def seed_everything(seed=1234):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","seed_everything()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"68aa1d6303e656ca76184d53c44001836c431939","scrolled":true,"trusted":true},"outputs":[],"source":["train_preds = np.zeros(len(train))\n","test_preds = np.zeros((len(test), len(splits)))\n","n_epochs = 5\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score\n","for i, (train_idx, valid_idx) in enumerate(splits):    \n","    x_train_fold = torch.tensor(X_train[train_idx], dtype=torch.long).cuda()\n","    y_train_fold = torch.tensor(y_train[train_idx, np.newaxis], dtype=torch.float32).cuda()\n","    x_val_fold = torch.tensor(X_train[valid_idx], dtype=torch.long).cuda()\n","    y_val_fold = torch.tensor(y_train[valid_idx, np.newaxis], dtype=torch.float32).cuda()\n","    \n","    train = torch.utils.data.TensorDataset(x_train_fold, y_train_fold)\n","    valid = torch.utils.data.TensorDataset(x_val_fold, y_val_fold)\n","    \n","    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n","    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n","    \n","    print(f'Fold {i + 1}')\n","    \n","    seed_everything(seed + i)\n","    model = NeuralNet()\n","    model.cuda()\n","\n","    valid_preds_fold, test_preds_fold = train_model(model,\n","                                                                           x_train_fold, \n","                                                                           y_train_fold, \n","                                                                           x_val_fold, \n","                                                                           y_val_fold, validate=False)\n","\n","    train_preds[valid_idx] = valid_preds_fold\n","    test_preds[:, i] = test_preds_fold\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["search_result = threshold_search(y_test, test_preds)\n","print(search_result)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"2c04e298f5c96a9561450874a0238f408984c39e","trusted":true},"outputs":[],"source":["search_result = threshold_search(y_train, train_preds)\n","sub['prediction'] = test_preds.mean(1) > search_result['threshold']\n","sub.to_csv(\"submission.csv\", index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":4}
